---
layout: post
title: "GLM-5 发布：专为复杂系统工程和长期智能体任务打造的开源大模型"
date: 2026-02-12 14:03:03 +0800
categories: tech-translation
description: "智谱 AI 发布 GLM-5 大模型，参数规模从 355B 扩展到 744B，在推理、编程和智能体任务上达到开源模型最佳性能，并采用 MIT 协议开源。"
original_url: https://z.ai/blog/glm-5
source: Hacker News
---

本文翻译自 [GLM-5: Designed for Complex Systems Engineering and Long-Horizon Agentic Tasks](https://z.ai/blog/glm-5)，原载于 Hacker News。

---

## 概述

智谱 AI（Zhipu AI）发布了新一代大语言模型 **GLM-5**，这是一个专为**复杂系统工程**和**长期智能体（Agent）任务**设计的开源模型。

在 AI 领域，Scaling（规模扩展）仍然是提升 AGI（通用人工智能）智能效率最重要的方式之一。相比 GLM-4.5，GLM-5 的参数规模从 355B（激活 32B）扩展到了 **744B（激活 40B）**，预训练数据也从 23T 增长到 **28.5T tokens**。

更值得关注的是，GLM-5 集成了 **DeepSeek Sparse Attention (DSA)** 技术，在保持长上下文能力的同时，显著降低了部署成本。

## 强化学习突破：slime 异步 RL 基础设施

强化学习（Reinforcement Learning，RL）的目标是弥合预训练模型"能力"与"卓越"之间的差距。然而，由于 RL 训练效率低下，大规模部署一直是个挑战。

为此，智谱团队开发了 **slime**——一种全新的**异步 RL 基础设施**，大幅提升了训练吞吐量和效率，使得更细粒度的后训练迭代成为可能。

得益于预训练和后训练的双重进步，GLM-5 在广泛的学术基准测试中相比 GLM-4.7 实现了显著提升，并在**推理、编程和智能体任务**上达到了全球开源模型的最佳性能，正在缩小与前沿闭源模型的差距。

## 性能基准测试

GLM-5 在多个关键基准测试中表现出色：

### 推理能力

| 基准测试 | GLM-5 | GLM-4.7 | DeepSeek-V3.2 | Claude Opus 4.5 |
|---------|-------|---------|---------------|-----------------|
| Humanity's Last Exam | 30.5 | 24.8 | 25.1 | 28.4 |
| Humanity's Last Exam (w/ Tools) | **50.4** | 42.8 | 40.8 | 43.4 |
| AIME 2026 I | 92.7 | 92.9 | 92.7 | 93.3 |
| HMMT Nov. 2025 | 96.9 | 93.5 | 90.2 | 91.7 |
| GPQA-Diamond | 86.0 | 85.7 | 82.4 | 87.0 |

### 编程能力

| 基准测试 | GLM-5 | GLM-4.7 | DeepSeek-V3.2 | Claude Opus 4.5 |
|---------|-------|---------|---------------|-----------------|
| SWE-bench Verified | 77.8 | 73.8 | 73.1 | **80.9** |
| SWE-bench Multilingual | 73.3 | 66.7 | 70.2 | **77.5** |
| Terminal-Bench 2.0 | **56.2** | 41.0 | 39.3 | 59.3 |
| CyberGym | 43.2 | 23.5 | 17.3 | **50.6** |

### 智能体能力

在 **Vending Bench 2**（一个衡量长期运营能力的基准测试）中，GLM-5 在开源模型中排名第一。这个测试要求模型运营一个模拟自动售货机业务长达一年，GLM-5 的最终账户余额达到 **$4,432**，接近 Claude Opus 4.5，展现出强大的长期规划和资源管理能力。

| 基准测试 | GLM-5 | 其他开源模型 |
|---------|-------|-------------|
| BrowseComp | 62.0 | - |
| BrowseComp (w/ Context Manage) | **75.9** | - |
| MCP-Atlas Public Set | 67.8 | - |
| Vending Bench 2 | **$4,432** | 开源第一 |

## Office 能力：从"对话"到"工作"

基础模型正在从"Chat"（对话）向"Work"（工作）演进，就像知识工作者的 Office 工具和工程师的编程工具一样。

GLM-5 可以将文本或源材料直接转换为 **.docx、.pdf 和 .xlsx** 文件——产品需求文档（PRD）、教案、试卷、电子表格、财务报告、执行清单、菜单等等——端到端地交付即用型文档。

智谱官方应用 Z.ai 正在推出 **Agent Mode**，内置 PDF/Word/Excel 创建技能，支持多轮协作，将输出转化为真正的交付物。

## 如何使用 GLM-5

### 通过编程助手使用

GLM-5 可以在多种编程助手（Coding Agents）中使用：**Claude Code、OpenCode、Kilo Code、Roo Code、Cline、Droid** 等。

对于 GLM Coding Plan 订阅用户：
- **Max 套餐用户**：现在可以通过将模型名更新为 `"GLM-5"` 来启用（如在 Claude Code 的 `~/.claude/settings.json` 中配置）
- **其他套餐**：将逐步开放支持
- **配额说明**：GLM-5 请求消耗的配额比 GLM-4.7 更多

### 通过 OpenClaw 使用

除了编程助手，GLM-5 还支持 **OpenClaw**——一个将 GLM-5 变成个人助手的框架，可以**跨应用和设备操作**，而不仅仅是对话。

### 在 Z.ai 上对话

GLM-5 可通过 Z.ai 访问，提供两种模式：
- **Chat Mode**：即时响应、交互式对话、轻量交付
- **Agent Mode**：多种工具、多样技能、直接交付结果

### 本地部署

GLM-5 的模型权重已在 **Hugging Face** 和 **ModelScope** 上公开发布，采用 **MIT License** 开源协议。

对于本地部署，GLM-5 支持 vLLM 和 SGLang 等推理框架，详细部署说明可在官方 GitHub 仓库找到。

值得一提的是，GLM-5 还支持在非 NVIDIA 芯片上部署，包括：
- 华为昇腾（Huawei Ascend）
- 摩尔线程（Moore Threads）
- 寒武纪（Cambricon）
- 昆仑芯片（Kunlun Chip）
- 壁仞（MetaX）
- 燧原（Enflame）
- 海光（Hygon）

通过算子优化和模型量化，GLM-5 可以在这些芯片上实现合理的吞吐量。

## 个人观点

GLM-5 的发布有几个值得关注的亮点：

1. **开源策略**：采用 MIT 协议开源 744B 参数的模型权重，这是相当激进的开放策略，有利于社区发展和应用落地。

2. **国产芯片支持**：对华为昇腾、摩尔线程等国产芯片的支持，显示了对算力自主可控的重视，这对于国内企业来说是个利好。

3. **异步 RL 基础设施**：slime 这个技术创新值得深入研究，异步 RL 可能是突破大模型后训练效率瓶颈的关键方向之一。

4. **DSA 集成**：稀疏注意力机制的应用，让大模型在保持长上下文能力的同时降低部署成本，这是工程实用化的重要一步。

5. **从 Chat 到 Work**：GLM-5 强调的 Office 能力，体现了大模型从"对话工具"向"生产力工具"演进的行业趋势。

## 总结

GLM-5 是智谱 AI 在大模型领域的重要里程碑。通过规模扩展、强化学习创新和稀疏注意力技术，GLM-5 在推理、编程和智能体任务上达到了开源模型的领先水平。MIT 协议的开源策略和对国产芯片的支持，将进一步推动国内 AI 生态的发展。

对于开发者来说，无论是通过 API、编程助手还是本地部署，GLM-5 都提供了灵活的使用方式。特别是对 Claude Code 等编程助手的支持，让开发者可以无缝集成到现有工作流程中。

---

*参考链接：*
- [GLM-5 官方博客](https://z.ai/blog/glm-5)
- [Hugging Face 模型页面](https://huggingface.co/collections/THUDM/glm-5)
- [Z.ai 开发者平台](https://api.z.ai)
