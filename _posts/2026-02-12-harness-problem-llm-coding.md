---
layout: post
title: "让 15 个 LLM 编程能力提升的秘诀：不是换模型，而是换工具"
date: 2026-02-12 23:12:39 +0800
categories: tech-translation
description: "一个下午，仅通过改变代码编辑工具的实现方式，就让 16 个大语言模型的编程成功率大幅提升。这篇文章揭示了「Harness 问题」——模型和用户之间的桥梁，才是 AI 编程工具真正的瓶颈所在。"
original_url: http://blog.can.ac/2026/02/12/the-harness-problem/
source: Hacker News
---

本文翻译自 [I Improved 15 LLMs at Coding in One Afternoon. Only the Harness Changed.](http://blog.can.ac/2026/02/12/the-harness-problem/)，原载于 Hacker News。

---

## 真正改变的只是编辑工具，仅此而已

当所有人都在讨论 GPT-5.3 和 Opus 谁更强、Gemini 和这周新出的模型谁更厉害时，这个框架越来越具有误导性。因为它把模型当作唯一重要的变量，而现实中真正的瓶颈之一是更平凡的东西：**Harness（工具框架）**。

所谓 Harness，就是你给模型展示代码、接收模型输出、并将更改应用到工作区的整个系统。它不仅决定了用户的第一印象（是疯狂滚动还是丝滑流畅），也是所有输入 token 的来源，更是模型输出与你工作区之间每次更改的接口。

## 当前主流的编辑方案

在介绍作者的创新之前，让我们看看目前业界的几种主流方案：

### Codex 的 `apply_patch`
采用 OpenAI 风格的 diff 字符串作为输入。问题是，给一个对此格式完全不了解的模型，patch 失败率会飙升。Grok 4 的 patch 失败率高达 **50.7%**，GLM-4.7 也有 **46.2%**。这些不是差模型——它们只是不说这门语言。

### Claude Code（以及大多数其他工具）的 `str_replace`
找到**精确**的旧文本，替换为新文本。简单易懂，但模型必须完美复现每个字符，包括空格和缩进。多个匹配？拒绝执行。"String to replace not found in file" 错误太常见了，甚至有自己的 GitHub issues 长帖。

### Cursor 的独立神经网络
专门 fine-tune 了一个 70B 模型来做合并工作。Harness 问题如此之难，以至于最有钱的 AI 公司之一决定再扔一个模型来解决它。

**这些工具的共同问题：没有给模型一个稳定、可验证的标识符来定位要修改的行，只能依赖模型的完美记忆。**

## Hashline：作者的创新方案

核心思想很简单：当模型读取文件或 grep 内容时，每行都带有一个 2-3 字符的内容哈希标签：

```
11:a3|function hello() {
22:f1| return "world";
33:0e|}
```

当模型编辑时，它引用这些标签——"替换行 `2:f1`，替换范围 `1:a3` 到 `3:0e`，在 `3:0e` 后插入"。

如果文件自上次读取后发生了变化，哈希值（乐观地）不会匹配，编辑会被拒绝——在损坏任何内容之前。

**关键优势：模型不需要复现旧内容，也不需要担心空格问题。只要能记住一个伪随机标签，就说明它知道自己在编辑什么。**

## 基准测试结果

作者使用 React 代码库进行测试：随机选取文件，引入 bug（运算符交换、布尔翻转、差一错误等），生成英文描述，让模型修复。

| 模型 | Patch | Replace | Hashline | Δ Patch | Δ Replace | Token 节省 |
|------|-------|---------|----------|---------|-----------|-----------|
| Gemini 3 Flash | 73.3% | 70.0% | 78.3% | +5.0 | +8.3 | -21% |
| Kimi K2.5 | 66.7% | 71.7% | 76.7% | +10.0 | +5.0 | -26% |
| GLM-4.7 | 51.7% | 66.7% | 71.7% | +20.0 | +5.0 | -32% |
| Claude Sonnet 4.5 | 65.6% | 76.7% | 78.3% | +12.7 | +1.6 | -24% |
| Grok Code Fast 1 | 6.7% | 66.7% | 68.3% | **+61.6** | +1.6 | -49% |
| MiniMax M2.1 | 23.3% | 55.0% | 55.0% | +31.7 | ±0.0 | -42% |

**Hashline 在 14/16 个模型上优于 Patch，同时通常节省 20-30% 的 token。**

最惊人的是 Grok Code Fast 1：从 6.7% 提升到 68.3%，**十倍改进**。Patch 失败太严重，以至于模型真正的编程能力完全被机械编辑失败掩盖了。

## 这意味着什么

**Gemini 成功率提升 8%，比大多数模型升级带来的提升都大，而且花费了零训练算力。**

通常模型不是不理解任务——它只是难以表达自己。你在怪飞行员，但问题出在起落架上。

## 关于厂商的态度

Anthropic 最近封锁了 OpenCode（一个流行的开源编程 agent）访问 Claude。Google 在作者运行基准测试时直接封禁了他的 Gemini 账户。

但这恰恰是短视的。作者刚刚展示了不同的编辑格式可以提升**他们自己的模型** 5-14 个百分点，同时减少约 20% 的输出 token。这不是威胁——这是免费的 R&D。

没有厂商会为竞争对手的模型优化 harness。Anthropic 不会为 Grok 调优，xAI 不会为 Gemini 调优，OpenAI 不会为 Claude 调优。但开源 harness 可以为所有模型调优，因为贡献者使用不同的模型并修复他们自己遇到的问题。

**模型是护城河。Harness 是桥梁。烧掉桥梁只会让更少的人愿意过河。**

---

## 总结

这篇文章揭示了一个被忽视的关键问题：

1. **Harness 问题真实存在**：模型和用户之间的接口层，是 AI 编程工具的主要瓶颈之一
2. **格式选择影响巨大**：仅改变编辑格式，就能让模型表现有天壤之别
3. **开源 harness 的价值**：只有开源社区能为所有模型优化，单一厂商只会为自己的模型优化
4. **"Cool demo" 和 "reliable tool" 之间的差距**：不是模型魔法，而是在工具边界的、相当无聊的、经验性的工程设计

下次当你的 AI 编程助手频繁失败时，在换模型之前，也许应该先看看是不是工具的问题。

*所有代码、基准测试和详细报告：[oh-my-pi](https://github.com/nick/oh-my-pi)*
