---
layout: post
title: "GLM-5 发布：面向复杂系统工程与长周期 Agent 任务的开源大模型"
date: 2026-02-12 21:08:58 +0800
categories: tech-translation
description: "智谱 AI 发布 GLM-5 大模型，744B 参数规模，在推理、编码和 Agent 任务上达到开源模型最佳性能，支持本地部署和多种推理框架。"
original_url: https://z.ai/blog/glm-5
source: Hacker News
---

本文翻译自 [GLM-5: Scaling to Excellence](https://z.ai/blog/glm-5)，原载于 Hacker News。

## 概述

智谱 AI（Zhipu AI）正式发布 GLM-5，这是一款专门面向复杂系统工程和长周期 Agent 任务的大语言模型。作为 GLM 系列的最新一代，GLM-5 在模型规模、训练数据和推理能力上都有显著提升。

## 规模与架构

Scaling（规模化）仍然是提升 AGI（通用人工智能）智能效率最重要的方式之一。与 GLM-4.5 相比，GLM-5 实现了显著的规模扩展：

| 指标 | GLM-4.5 | GLM-5 |
|------|---------|-------|
| 总参数量 | 355B | 744B |
| 激活参数 | 32B | 40B |
| 预训练数据 | 23T tokens | 28.5T tokens |

GLM-5 还集成了 DeepSeek Sparse Attention (DSA) 技术，在保持长上下文能力的同时显著降低了部署成本。

## 创新的异步 RL 基础设施

强化学习（Reinforcement Learning）旨在弥合预训练模型从"能力"到"卓越"之间的差距。然而，由于 RL 训练效率低下，将其大规模应用于 LLM 一直是个挑战。

为此，GLM 团队开发了 **slime** —— 一种新颖的**异步 RL 基础设施**，大幅提升了训练吞吐量和效率，使更细粒度的后训练迭代成为可能。

## 性能表现

GLM-5 在广泛的学术基准测试中相比 GLM-4.7 有显著提升，并在推理、编码和 Agent 任务上实现了全球开源模型中的最佳性能，正在缩小与前沿模型的差距。

### 推理能力

| 基准测试 | GLM-5 | GLM-4.7 | DeepSeek-V3.2 | Claude Opus 4.5 |
|----------|-------|---------|---------------|-----------------|
| Humanity's Last Exam | 30.5 | 24.8 | 25.1 | 28.4 |
| Humanity's Last Exam w/ Tools | 50.4 | 42.8 | 40.8 | 43.4 |
| AIME 2026 I | 92.7 | 92.9 | 92.7 | 93.3 |
| HMMT Nov. 2025 | 96.9 | 93.5 | 90.2 | 91.7 |
| GPQA-Diamond | 86.0 | 85.7 | 82.4 | 87.0 |

### 编码能力

| 基准测试 | GLM-5 | GLM-4.7 | Claude Opus 4.5 |
|----------|-------|---------|-----------------|
| SWE-bench Verified | 77.8 | 73.8 | 80.9 |
| SWE-bench Multilingual | 73.3 | 66.7 | 77.5 |
| Terminal-Bench 2.0 | 56.2 | 41.0 | 59.3 |
| CyberGym | 43.2 | 23.5 | 50.6 |

### Agent 能力

GLM-5 在长周期 Agent 任务上表现尤为出色：

| 基准测试 | GLM-5 | GLM-4.7 | Claude Opus 4.5 |
|----------|-------|---------|-----------------|
| BrowseComp | 62.0 | 52.0 | 37.0 |
| BrowseComp w/ Context | 75.9 | 67.5 | 67.8 |
| τ²-Bench | 89.7 | 87.4 | 91.6 |
| MCP-Atlas | 67.8 | 52.0 | 65.2 |

**Vending Bench 2** 是一个衡量长期运营能力的基准测试，要求模型在一年时间跨度内运营一个模拟的自动售货机业务。GLM-5 以 $4,432 的最终账户余额排名开源模型第一，接近 Claude Opus 4.5 的 $4,967，展示了强大的长期规划和资源管理能力。

## Office 能力：从"对话"到"工作"

基础模型正在从"聊天"转向"工作"，就像知识工作者的 Office 工具和工程师的编程工具一样。

GLM-5 可以将文本或源材料直接转换为 .docx、.pdf 和 .xlsx 文件——PRD、教案、试卷、电子表格、财务报告、运行表、菜单等——端到端交付即用的文档。

Z.ai 官方应用正在推出 Agent 模式，内置 PDF/Word/Excel 创建技能，支持多轮协作并将输出转化为真正的可交付成果。

## 如何使用 GLM-5

### 编程 Agent 集成

GLM-5 支持多种主流编程 Agent：
- Claude Code
- OpenCode
- Kilo Code
- Roo Code
- Cline
- Droid

**Max 计划用户**现在可以通过将模型名称更新为 `"GLM-5"` 来启用 GLM-5（例如在 Claude Code 的 `~/.claude/settings.json` 中）。

### OpenClaw 支持

GLM-5 还支持 **OpenClaw** —— 一个将 GLM-5 转变为**跨应用和设备操作**的个人助理框架，而不仅仅是聊天。

### 在线体验

GLM-5 可通过 [Z.ai](https://z.ai) 访问，提供两种模式：
- **Chat 模式**：即时响应、交互式聊天、轻量交付
- **Agent 模式**：多工具、多技能、直接交付结果

### 本地部署

GLM-5 的模型权重已在 Hugging Face 和 ModelScope 上公开可用，采用 MIT 许可证。本地部署支持 vLLM 和 SGLang 等推理框架。

此外，GLM-5 还支持在非 NVIDIA 芯片上部署，包括华为昇腾、摩尔线程、寒武纪、昆仑芯、MetaX、燧原和海光。通过算子优化和模型量化，GLM-5 可以在这些芯片上实现合理的吞吐量。

## 个人点评

GLM-5 的发布有几个值得关注的亮点：

1. **长周期 Agent 能力**：Vending Bench 2 的表现说明 GLM-5 在需要持续规划和决策的任务上有很强的能力，这对于实际的生产环境应用非常重要。

2. **开源策略**：采用 MIT 许可证发布权重，这对于开发者和企业来说是一个重大利好，意味着更灵活的商业化可能性。

3. **多芯片支持**：支持华为昇腾、寒武纪等国产芯片，这对于国内企业来说具有重要的战略意义。

4. **异步 RL 基础设施**：slime 的开发解决了 RL 训练效率的问题，这可能是 GLM-5 性能提升的关键因素之一。

不过，从基准测试数据来看，GLM-5 与 Claude Opus 4.5 和 GPT-5.2 之间仍有一定差距，特别是在某些推理任务上。开源模型要完全追赶上前沿模型，还需要持续的努力。

---

**关键要点：**
- GLM-5 参数规模 744B（40B 激活），预训练数据 28.5T tokens
- 在开源模型中推理、编码、Agent 任务性能最佳
- 支持本地部署、MIT 许可证、多芯片适配
- 长周期 Agent 任务表现接近 Claude Opus 4.5
